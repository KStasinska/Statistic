---
title: "Sprawozdanie 2 Modele liniowe"
author: "Katarzyna Stasińska"
date: '2023'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# zadanie 1

Patrząc na wykres poniżej można stwierdzić, że zależność jest w przybliżeniu liniowa.

```{r,echo=FALSE}
path='/home/kasia/Desktop/Modele/CH01PR20.txt'
dane=read.table(path,col.names=c("hours", "size"))
plot(hours~size,dane)
```

# zadanie 2

Estimated regression equation jest opisane wzorem $Y_{i}=b_0+b_1X_{i}+\epsilon_{i}$, gdzie $b_0$ to wyraz wolny (intercept), $b_1$ to nachylenie (slope), oba są parametrami deterministycznymi, a $\epsilon_{i}$ to zmienna losowa z rozkładu $N(0,\sigma^{2})$. Prosta regresji została oznaczona na wykresie kolorem zielonym.

```{r,echo=FALSE}
plot(hours~size, dane)
reg1=lm(hours~size, dane)
intercept=reg1$coefficients[1]
slope=reg1$coefficients[2]
abline(intercept,slope,col='green')
cat("Korzystając z funkcji wbudowanych intercept = ",intercept,", a slope = ",slope)
```

Spróbujmy wyliczyć wartości tych parametrów korzystając z wiedzy teoretycznej.

```{r,echo=TRUE}
slope=sum((dane$size-mean(dane$size))*(dane$hours-mean(dane$hours)))/sum((dane$size-mean(dane$size))^2)
intercept=mean(dane$hours-slope*mean(dane$size))
```
```{r,echo=FALSE}
cat("Korzystając ze wzorów z wykładu intercept = ",intercept,", a slope = ",slope)
```

# zadanie 3

Korzystając z funkcji wbudowanych możemy wyznaczyć przedziały ufności slope'a i intercepta.

```{r,echo=FALSE}
a=confint(reg1)
cat("Przedziały ufności intercept = (",a[1,1],",",a[1,2],") slope = (",a[2,1],",",a[2,2],")")
```

Wyliczmy je wykorzystując teoretyczną wiedzę z wykładu.

```{r,echo=TRUE}
kwantyl=qt(0.975, length(dane$hours)-2)
s2=sum((dane$hours-intercept-slope*dane$size)^2)/(length(dane$hours)-2)
s2b1=s2/sum((dane$size-mean(dane$size))^2)
leftslope=slope-kwantyl*s2b1^(1/2)
rightslope=slope+kwantyl*s2b1^(1/2)
s2b0=s2*(1/length(dane$size)+(mean(dane$size))^2/sum((dane$size-mean(dane$size))^2))
leftintercept=intercept-kwantyl*s2b0^(1/2)
rightintercept=intercept+kwantyl*s2b0^(1/2)
```

```{r,echo=FALSE}
cat("Przedziały ufności intercept = (",leftintercept,",",rightintercept,") slope = (",leftslope,",",rightslope,")")
```

# zadanie 4

Ustalmy poziom istotności $\alpha=0,05$

### Test istotności slope'a korzystając z poleceń wbudowanych. 

Hipotezy: $H_{0}: \beta_{1}=0$ \quad $H_{1}: \beta_{1} \ne 0$

```{r, echo=FALSE}
pintercept=summary(reg1)$coefficients["(Intercept)", "Pr(>|t|)"]
pslope=summary(reg1)$coefficients["size", "Pr(>|t|)"]
tintercept=summary(reg1)$coefficients["(Intercept)", "t value"]
tslope=summary(reg1)$coefficients["size", "t value"]
```

```{r,echo=FALSE}
cat("statystyka testowa:",tslope,", p-wartosc:",pslope)
```

Możemy zauważyć, że $p<\alpha$, zatem odrzucamy hipotezę $H_{0}$, istnieje relacja między X a Y.

### Test istotności slope'a korzystając ze wzorów teoretycznych.

Hipotezy: $H_{0}: \beta_{1}=0$ \quad $H_{1}: \beta_{1} \ne 0$

```{r,echo=TRUE}
tslope=slope/(s2b1)^(1/2)
pslope=2*(1-pt(abs(tslope),length(dane$size)-2))
```
```{r,echo=FALSE}
cat("statystyka testowa:",tslope,", p-wartosc:",pslope)
```

Możemy zauważyć, że i w tym przypadku $p<\alpha$, choć zgubiliśmy gdzieś dokładność, bo $p=0$, a nie jest bardzo bliskie zera. Ponownie odrzucamy hipotezę $H_{0}$, istnieje relacja między X a Y.

### Test istotności intercepta korzystając z poleceń wbudowanych. 

Hipotezy: $H_{0}: \beta_{0}=0$ \quad $H_{1}: \beta_{0} \ne 0$

```{r,echo=FALSE}
cat("statystyka testowa:",tintercept,", p-wartosc:",pintercept)
```

Zauważmy, że $p>\alpha$, nie możemy odrzucić hipotezy $H_{0}$, nie wiemy czy X i Y są wzajemnie proporcjonalne.

### Test istotności intercepta korzystając ze wzorów teoretycznych.

Hipotezy: $H_{0}: \beta_{0}=0$ \quad $H_{1}: \beta_{0} \ne 0$

```{r,echo=TRUE}
tintercept=intercept/(s2b0)^(1/2)
pintercept=2*(1-pt(abs(tintercept),length(dane$size)-2))
```
```{r,echo=FALSE}
cat("statystyka testowa:",tintercept,", p-wartosc:",pintercept)
```

Wyniki są takie same jak przy użyciu funkcji wbudowanych, stąd i wnioski są takie same, nie możemy odrzucić hipotezy $H_{0}$.

Wykorzystuję statystyki testowe z $n-2$ stopniami swobody, gdzie $n$ to rozmiar danych.

# zadanie 5

Niech $E(Y_{h})=\mu_{h}$, zatem estymator wartości oczekiwanej wyraża się wzorem $\hat\mu_{h}=\hat\beta_{0}+\hat\beta_{1}X_{h}$.

Wyniki eksperymentu przeprowadzonego przy pomocy funkcji wbudowanych.

```{r,echo=FALSE}
k_values <- c(1, 2, 4, 5, 6, 7, 8, 11, 25, 100)

for (k in k_values) {
  new_data <- data.frame(size = k)
  pred <- predict(reg1, newdata = new_data, interval = "confidence", level = 0.95)
  
  cat(paste("Wartość estymatora wartości oczekiwanej czasu obsługi:", pred[1], "\n"))
  cat(paste("Przedział ufności dla k=", k, "[", pred[2], ",", pred[3], "]\n"))
  cat(paste("Długość przedziału:", pred[3] - pred[2], "\n\n"))
}
```

Wyniki eksperymentu przy użyciu zaimplementowanych wzorów z wykładu.

```{r,echo=TRUE}
for (k in c(1, 2, 4, 5, 6, 7, 8, 11, 25, 100)){
  mu=intercept+slope*k
  smu2=s2*(1/length(dane$size)+(k-mean(dane$size))^2/(sum((dane$size-mean(dane$size))^2)))
  left=mu-kwantyl*smu2^(1/2)
  right=mu+kwantyl*smu2^(1/2)
  cat(paste("Wartość estymatora wartości oczekiwanej czasu obsługi:",mu,"\n"))
  cat(paste("Przedział ufności dla k=",k,"[",left,",",right,"]\n")) 
  cat(paste("Długość przedziału=",right-left,"\n\n"))
}
```
Im współrzędna x-owa punktu bliższa średniej wartości współrzędnej x-owej po wszystkich punktach, tym krótszy przedział ufności. Co zgadza się z teorią z wykładu, wpływ na długość przedziału ma $s(\hat\mu_{h})$, które z kolei zależy od $(X_{h}-\bar{X})^{2}$. Średnia wartość współrzędnej x-owej po wszystkich punktach $=5.111111$, stąd dla $k=5$ możemy zaobserwować najkrótszy przedział ufności.

# zadanie 6

Wartości przewidywanego czasu obsługi również wyrażają się wzorem $\hat Y_{h}=\hat\mu_{h}=\hat\beta_{0}+\hat\beta_{1}X_{h}$.

Wyniki eksperymentu przeprowadzonego przy pomocy funkcji wbudowanych.

```{r,echo=FALSE}
k_values <- c(1, 2, 4, 5, 6, 7, 8, 11, 25, 100)

for (k in k_values) {
  new_data <- data.frame(size = k)
  pred <- predict(reg1, newdata = new_data, interval = "prediction", level = 0.95)
  
  cat(paste("Wartość estymatora wartości oczekiwanej czasu obsługi:", pred[1], "\n"))
  cat(paste("Przedział ufności dla k=", k, "[", pred[2], ",", pred[3], "]\n"))
  cat(paste("Długość przedziału:", pred[3] - pred[2], "\n\n"))
}
```

Wyniki eksperymentu przy użyciu zaimplementowanych wzorów z wykładu.

```{r,echo=TRUE}
for (k in c(1, 2, 4, 5, 6, 7, 8, 11, 25, 100)){
  mu=intercept+slope*k
  spred2=s2*(1+1/length(dane$size)+(k-mean(dane$size))^2/(sum((dane$size-mean(dane$size))^2)))
  left=mu-kwantyl*spred2^(1/2)
  right=mu+kwantyl*spred2^(1/2)
  cat(paste("Przewidywany czas obsługi:",mu,"\n"))
  cat(paste("Przedział ufności dla k=",k,"[",left,",",right,"]\n")) 
  cat(paste("Długość przedziału=",right-left,"\n\n"))
}
```

Przedziały predykcyjne są znacząco dłuższe od przedziałów ufności. Zależność między długością przedziałów predykcyjnych jest taka sama, jak zależność między długością przedziałów ufności. Im współrzędna x-owa punktu bliższa średniej wartości współrzędnej x-owej po wszystkich punktach, tym krótszy przedział predykcyjny. Wynika to z tego samego argumentu co w zadaniu 5.

# zadanie 7

Na wykresie poniżej, czerwony kolor wyznacza przedziały predykcyjne, a niebieski przedziały ufności.

```{r,echo=FALSE}
new_data <- seq(min(dane$size),max(dane$size),by = 0.05)
conf <- predict(reg1, newdata = data.frame(size = new_data), interval = "confidence", level = 0.95)
pred <- predict(reg1, newdata = data.frame(size = new_data), interval = "prediction", level = 0.95)
plot(hours~size, dane)
abline(intercept,slope,col='green')
matlines(new_data, conf[,2:3], col = "blue", lty=2)
matlines(new_data, pred[,2:3], col = "red", lty=2)

```

Przedziały ufności są zawsze mniejsze od przedziałów predykcyjnych, ponieważ wpływ na długość przedziału ma wariancja (im większa tym dłuższy przedział). A wariancja błędu predykcji zmiennej Y jest większa od wariancji estymatora $\hat\mu_{h}$

$Var(Y_{h}-\hat\mu_{h})=Var(Y_{h})+Var(\hat\mu_{h})>Var(\hat\mu_{h})$, bo wariancja jest nieujemna.

# zadanie 8

## a)

Rozważamy hipotezy: $H_{0}: \beta_{1}=0$ \quad $H_{1}: \beta_{1}=1$
Wyliczmy wartość $\pi(a)=P_{\beta_{1}=a}(|T|>t_{c})$ dla $a=1$

```{r,echo=TRUE}
beta1 = 1
n = 40
s2 = 70
SSX = 500
s2b1 = s2/SSX
delta = beta1 / sqrt(s2/SSX)
kwantyl=qt(0.975,n-2)
power=pt(-kwantyl, n-2, ncp = delta) + 1 - pt(kwantyl, n-2, ncp = delta)
power
```

## b)
```{r,echo=FALSE}
library(ggplot2)
beta1_values <- seq(-2, 2, by = 0.1)
data2 <- data.frame(beta1 = beta1_values)
calculate_power <- function(beta1) {
  delta <- beta1 / sqrt(s2/SSX)
  power <- suppressWarnings(pt(-kwantyl, n - 2, ncp = delta)) + 1 - suppressWarnings(pt(kwantyl, n - 2, ncp = delta))
  return(power)
}

data2$power <- sapply(data2$beta1, calculate_power)
ggplot(data2, aes(x = beta1, y = power)) +
  geom_line() +
  labs(x = "beta1",
       y = "power")
```

## c)

```{r,echo=FALSE}
s2=120
beta1_values <- seq(-2, 2, by = 0.1)
data2 <- data.frame(beta1 = beta1_values)
calculate_power <- function(beta1) {
  delta <- beta1 / sqrt(s2/SSX)
  power <- suppressWarnings(pt(-kwantyl, n - 2, ncp = delta)) + 1 - suppressWarnings(pt(kwantyl, n - 2, ncp = delta))
  return(power)
}

data2$power <- sapply(data2$beta1, calculate_power)
ggplot(data2, aes(x = beta1, y = power)) +
  geom_line() +
  labs(x = "beta1",
       y = "power")
```

Zmiana wartości parametru $\sigma^{2}$ na większy wypłaszczyła wykres. Wzrosty i spadki nie są już aż tak gwałtowne.

# zadanie 9

```{r,echo=FALSE}
library(MASS)
set.seed(123)
run_experiment <- function(n, beta1, distribution) {
  mean = rep(c(0),200)
  var = diag(200)/500
  X = mvrnorm(1, mean,var)
  if (distribution == "normal") {
    epsilon <- rnorm(n, mean = 0, sd = 1)
  } else if (distribution == "exponential") {
    epsilon <- rexp(n, rate = 1)
  } else if (distribution == "logistic") {
    epsilon <- rlogis(n, location = 0, scale = 1)
  }
  Y <- 5 + beta1 * X + epsilon
  p_value <- summary(lm(Y ~ X))$coefficients[2, 4]
  return(p_value < 0.05)
}
conditions <- c("normal", "exponential", "logistic")
beta_values <- c(0, 2)
num_simulations <- 1000
results <- matrix(NA, nrow = length(conditions), ncol = length(beta_values))
for (i in seq_along(conditions)) {
  for (j in seq_along(beta_values)) {
    condition <- conditions[i]
    beta_value <- beta_values[j]
    simulations <- replicate(num_simulations, run_experiment(200, beta_value, condition))
    results[i, j] <- mean(simulations)
  }
}
rownames(results) <- conditions
colnames(results) <- paste("Beta =", beta_values)
print(results)
```

Hipotezę zerową odrzucam, gdy p-value jest mniejsze od $\alpha=0.05$. Teoretycznie błąd pierwszego rodzaju jest równy parametrowi istotności $\alpha$. Uzyskane wyniki są bardzo bliskiej tej wartości. Wyliczmy teoretyczne wartości funkcji mocy dla przykładów d), e) i f).

```{r,echo=FALSE}
beta1 = 2
n = 200
mean = rep(c(0),200)
var = diag(200)/500
X = mvrnorm(1, mean,var)
SSX = sum((X-mean(X))^2)
s2 = c(1,1,pi^2/3)
for (i in 1:3){
  s2b1 = s2[i]/SSX
  delta = beta1 / sqrt(s2[i]/SSX)
  kwantyl=qt(0.975,n-2)
  power=pt(-kwantyl, n-2, ncp = delta) + 1 - pt(kwantyl, n-2, ncp = delta)
  cat("Moc wynosi:",power,"\n")
}
```

Możemy zwrócić uwagę, że teoretyczna moc jest bliska wynikom eksperymentu, szczególnie w przypadku f).

# Zadania teoretyczne

## zadanie 1

```{r,echo=TRUE}
cat(kwantyl=qt(0.975, 18))
```

Przedziały ufności $\beta_{1}$ wyrażają się wzorem $b_{1} \pm t_{c}s(b_{1})$. Podstawiając dane z zadania do wzoru otrzymujemy lewy koniec przedziału $=3-t_{c}=0.899078$ i prawy koniec przedziału  $=3+t_{c}=5.100922$.

## zadanie 2
Rozważmy test istotości $\hat\beta_{1}$.

Hipotezy: $H_{0}: \beta_{1}=0$ \quad $H_{1}: \beta_{1} \ne 0$

$T=\frac{\hat\beta_{1}}{s(\hat\beta_{1})}=3$
Jeśli $|T|>t_{c}$, gdzie $t_{c}$ to kwantyl rzędu $1- \alpha/2$ z 18 stopniami swobody, to odrzucamy hipotezę zerową. Zakładając, że rząd $=0.975$ otrzymujemy $t_{c}=2.100922$. Zatem zachodzi $|T|>t_{c}$, odrzucamy hipotezę zerową, X i Y są zależne.

## zadanie 3

Z treści zadania wiemy, że $\hat\mu=16$, bo jest to środek przedziału ufności, zatem $t_{c}s(\hat\mu)=3$. Aby wyznaczyć predykcyjny przedział ufności potrzebujemy informacji o $s(pred)$. Zwróćmy uwagę, że 
\begin{align}
s^2(pred) - s^2(\hat{\mu}) &= s^2 \\
t_c^2 \cdot s^2(pred) - t_c^2 \cdot s^2(\hat{\mu}) &= t_c^2 \cdot s^2 \\
t_c^2 \cdot s^2(pred) - 9 &= t_c^2 \cdot s^2 \\
t_c \cdot s(pred) &= \sqrt{t_c^2 \cdot s^2 + 9}
\end{align}
Wiemy, że $t_{c}=2.100922$ oraz $s=4$, zatem $t_{c}s(pred)=8.923115$. Szukany przedział predykcyjny wynosi $[7.076885,24.92311]$.
